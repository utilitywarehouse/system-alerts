# PROMETHEUS RULES
# DO NOT REMOVE line above, used in `pre-commit` hook

groups:
  - name: pubsub-msk
    rules:
      - alert: MSKUnderReplicatedPartitions
        expr: kafka_topic_partition_under_replicated_partition{app_kubernetes_io_component="msk-metrics", kubernetes_namespace='pubsub'} > 0
        for: 30m
        labels:
          team: infra
          group: kafka
        annotations:
          summary: "In MSK instance {{ $labels.app_kubernetes_io_name }} kafka topic {{ $labels.topic }}, partition {{ $labels.partition }} is under replicated"
          dashboard: "https://grafana.$ENVIRONMENT.$PROVIDER.uw.systems/d/rrE2HgHVz/msk-kafka-metrics?orgId=1&viewPanel=684"
          runbook: "https://github.com/utilitywarehouse/documentation/blob/master/infra/operational/msk-ops.md#msk-under-replicated-partitions"
          priority: P1
      - alert: MSKAbnormalControllerState
        expr: sum by (job) (kafka_controller_KafkaController_Value{name="ActiveControllerCount", job=~"msk.*"}) != 1
        for: 5m
        labels:
          team: infra
          group: kafka
        annotations:
          summary: "In MSK instance {{ $labels.job }}, there are {{ $value }} active controllers"
          dashboard: "https://grafana.$ENVIRONMENT.$PROVIDER.uw.systems/d/rrE2HgHVz/msk-kafka-metrics?orgId=1"
          runbook: "https://github.com/utilitywarehouse/documentation/blob/master/infra/operational/msk-ops.md#msk-abnormal-controller-state"
          priority: P1
      - alert: MSKOfflinePartitions
        expr: sum by (job) (kafka_controller_KafkaController_Value{name="OfflinePartitionsCount", job=~"msk.*"}) > 0
        for: 5m
        labels:
          team: infra
          group: kafka
        annotations:
          summary: "In MSK instance {{ $labels.job }}, there are {{ $value }} offline partitions. They have no leader"
          dashboard: "https://grafana.$ENVIRONMENT.$PROVIDER.uw.systems/d/rrE2HgHVz/msk-kafka-metrics?orgId=1"
          runbook: "https://github.com/utilitywarehouse/documentation/blob/master/infra/operational/msk-ops.md#msk-offline-partitions"
          priority: P1
      - alert: MSKUnderMinIsrPartitionCount
        expr: kafka_server_ReplicaManager_Value{name="UnderMinIsrPartitionCount", job=~"msk.*"} > 0
        for: 5m
        labels:
          team: infra
          group: kafka
        annotations:
          summary: "In MSK instance {{ $labels.job }}, there are {{ $value }} partitions under min In Sync Replica."
          dashboard: "https://grafana.$ENVIRONMENT.$PROVIDER.uw.systems/d/rrE2HgHVz/msk-kafka-metrics?orgId=1"
          runbook: "https://github.com/utilitywarehouse/documentation/blob/master/infra/operational/msk-ops.md#msk-under-min-isr-partition-count"
          priority: P1
      - alert: MSKLowStorage
        # trigger on predict liner for 3d and when available space is less than 25%, as the autoscaling kicks in at 35%
        expr: predict_linear(node_filesystem_avail_bytes{job=~"msk-.*", mountpoint="/kafka/datalogs"}[1h], 72 * 3600) < 0 and (node_filesystem_avail_bytes{job=~"msk-.*", mountpoint="/kafka/datalogs"}/node_filesystem_size_bytes{job=~"msk-.*", mountpoint="/kafka/datalogs"} < 0.25)
        labels:
          team: infra
          group: kafka
        annotations:
          summary: "In MSK cluster {{ $labels.job }}, the instance {{ $labels.instance}} will run out of space in less than 3 days. Autoscaling already kicked in."
          runbook: "https://github.com/utilitywarehouse/documentation/blob/master/infra/operational/msk-ops.md#msk-low-storage"
          dashboard: "https://grafana.$ENVIRONMENT.$PROVIDER.uw.systems/d/rrE2HgHVz/msk-kafka-metrics?orgId=1&refresh=30s&viewPanel=83"
          priority: P1
      - alert: MSKStorageChanged
        # keep the alert open for 5h, so that we'll catch all autoscaling events which have a cooldown period of 6h
        expr: node_filesystem_size_bytes{job=~"msk-.*", mountpoint="/kafka/datalogs"} != node_filesystem_size_bytes{job=~"msk-.*", mountpoint="/kafka/datalogs"} offset 5h
        labels:
          team: infra
          group: kafka
        annotations:
          summary: "In MSK cluster {{ $labels.job }}, the local storage size has changed automatically or manually. The terraform project might need update"
          runbook: "https://github.com/utilitywarehouse/documentation/blob/master/infra/operational/msk-ops.md#msk-storage-changed"
          dashboard: "https://grafana.$ENVIRONMENT.$PROVIDER.uw.systems/d/rrE2HgHVz/msk-kafka-metrics?orgId=1&refresh=30s&viewPanel=83"
          priority: P2
      - alert: MSKCPULoad
        # From https://docs.aws.amazon.com/msk/latest/developerguide/bestpractices.html#bestpractices-monitor-cpu
        # Amazon MSK strongly recommends that you maintain the CPU utilization for your brokers (defined as CPU User + CPU System) under 60%
        expr: avg by (instance) (irate(node_cpu_seconds_total{mode="system", job=~"msk-.*"}[5m]) * 100) + avg by (instance) (irate(node_cpu_seconds_total{mode="user", job=~"msk-.*"}[5m]) * 100) > 60
        # For not triggering during patching: using 2 x patch window (3 min) for a single broker
        for: 6m
        labels:
          team: infra
          group: kafka
        annotations:
          summary: "In MSK cluster {{ $labels.job }}, the instance {{ $labels.instance}} is using more than 60% CPU"
          runbook: "https://github.com/utilitywarehouse/documentation/blob/master/infra/operational/msk-ops.md#mskcpu-load"
          dashboard: "https://grafana.$ENVIRONMENT.$PROVIDER.uw.systems/d/rrE2HgHVz/msk-kafka-metrics?orgId=1&refresh=30s&viewPanel=81"
          priority: P2
