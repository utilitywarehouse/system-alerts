# PROMETHEUS RULES
# DO NOT REMOVE line above, used in `pre-commit` hook

groups:
  - name: MissingReplicas
    rules:
      - alert: DeploymentMissingReplicas
        expr: kube_deployment_status_replicas_available != kube_deployment_status_replicas
        for: 15m
        labels:
          group: missing_replicas
        annotations:
          summary: "Deployment {{$labels.namespace}}/{{$labels.deployment}} has missing replicas for 15m"
          impact: "Workload may be unavailable or have lost high availability"
          action: "Check why some replicas are not healthy"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe deployment {{ $labels.deployment }}"
      - alert: StatefulsetMissingReplicas
        expr: kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
        for: 15m
        labels:
          group: missing_replicas
        annotations:
          summary: "Statefulset {{$labels.namespace}}/{{$labels.statefulset}} has missing replicas for 15m"
          impact: "Workload may be unavailable or have lost high availability"
          action: "Check why some replicas are not healthy"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe statefulset {{ $labels.statefulset }}"
      - alert: DaemonsetMissingReplicas
        # Alert if there are unhealthy replicas and the ds is not updating it's replicas
        expr: (kube_daemonset_status_number_ready != kube_daemonset_status_desired_number_scheduled) and changes(kube_daemonset_status_updated_number_scheduled[10m]) == 0
        for: 5m
        labels:
          group: missing_replicas
        annotations:
          summary: "Daemonset {{$labels.namespace}}/{{$labels.daemonset}} has missing replicas"
          impact: "Workload unavailable on some nodes"
          action: "Check why some replicas are not healthy"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe daemonset {{ $labels.daemonset }}"
      - alert: DeploymentMissingAllReplicas
        expr: kube_deployment_status_replicas_available == 0 and kube_deployment_status_replicas != 0
        for: 5m
        labels:
          group: missing_replicas
        annotations:
          summary: "Deployment {{$labels.namespace}}/{{$labels.deployment}} has 0 healthy replicas."
          impact: "Workload is down"
          action: "Check why all replicas are missing"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe deployment {{ $labels.deployment }}"
      - alert: StatefulsetMissingAllReplicas
        expr: kube_statefulset_status_replicas_ready == 0 and kube_statefulset_status_replicas != 0
        for: 5m
        labels:
          group: missing_replicas
        annotations:
          summary: "Statefulset {{$labels.namespace}}/{{$labels.statefulset}} has 0 healthy replicas."
          impact: "Workload is down"
          action: "Check why all replicas are missing"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe statefulset {{ $labels.statefulset }}"
      - alert: DaemonsetMissingAllReplicas
        expr: kube_daemonset_status_number_ready == 0 and kube_daemonset_status_desired_number_scheduled != 0
        for: 5m
        labels:
          group: missing_replicas
        annotations:
          summary: "Daemonset {{$labels.namespace}}/{{$labels.daemonset}} has 0 healthy replicas."
          impact: "Workload is down"
          action: "Check why all replicas are missing"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe daemonset {{ $labels.daemonset }}"
